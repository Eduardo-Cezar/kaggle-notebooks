{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2u_3s3yGsXF"
   },
   "source": [
    "### Descrição do dataset\n",
    "\n",
    "O dataset uitilizado se encontra no endereço: https://www.kaggle.com/burak3ergun/loan-data-set\n",
    "\n",
    "O problema em questão é: uma empressa de emprestimos deseja automatizar a validação de elegibilidade de um cliente que deseja realizar um empréstimo.\n",
    "\n",
    "Para resolver esse ploblema criei a rede neural para realizar a clasificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IJSazRK41Sc"
   },
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorrt in /home/eduardo/.cari/venv/jupyter/4.0.11/lib/python3.10/site-packages (8.6.1.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Gjv8ElVKkour"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras  \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bA5vu4K346E-"
   },
   "source": [
    "### Carregando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "whpCtpFdkous"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"loan_data_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "VRWf6Bczkous",
    "outputId": "72e6e24a-2b0e-4ef9-9b6d-fbaec2f74bf4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6cDrFUSlIgQ"
   },
   "source": [
    "Imprimindo as informações do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vXllriYlOA9",
    "outputId": "e31e2573-3ff0-4aa3-cc64-2a6e32b55d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjvV7o1t5ojW"
   },
   "source": [
    "## Checando a integridade do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AjJRaiwB8OH"
   },
   "source": [
    "Checando se existem valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_022JdSLCBVQ",
    "outputId": "ff87bfe2-baf0-45df-a969-43cafce544f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4A8b5vY7WT_"
   },
   "source": [
    "Checando quais são os valores majoritarios de cada atributo que possui dados faltantes, para completarmos os dados faltantes com eles.\n",
    "\n",
    "De acordo com a célula acima, são eles `Gender`,`Married`, `Dependents`,`Self_Employed`,`LoanAmount`,`Loan_Amount_Term` e `Credit_History`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GU9GGr1F6p_D",
    "outputId": "ff24ee13-a97a-4b1e-db64-b420083c87b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      489\n",
       "Female    112\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVlN6EnL9ETk",
    "outputId": "63c702e2-7618-4335-ed8f-65ffa9821fe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Married\n",
       "Yes    398\n",
       "No     213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Married'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9jey5tR9Sj-",
    "outputId": "231fc3bd-976e-4fe5-d326-39cb5fc64fb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dependents\n",
       "0     345\n",
       "1     102\n",
       "2     101\n",
       "3+     51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Dependents'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4hU9bd3vwJN",
    "outputId": "1fc66857-9226-464c-ac4c-5644ba5cb279"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Self_Employed\n",
       "No     500\n",
       "Yes     82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Self_Employed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sa1euq2v1Aq",
    "outputId": "9147ec02-6026-421e-8afb-cefae3c430ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoanAmount\n",
       "120.0    20\n",
       "110.0    17\n",
       "100.0    15\n",
       "160.0    12\n",
       "187.0    12\n",
       "         ..\n",
       "240.0     1\n",
       "214.0     1\n",
       "59.0      1\n",
       "166.0     1\n",
       "253.0     1\n",
       "Name: count, Length: 203, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['LoanAmount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Asip6m-vwIdi",
    "outputId": "7fd3212d-ddb9-44fb-ae27-a7c70f040ad6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_Amount_Term\n",
       "360.0    512\n",
       "180.0     44\n",
       "480.0     15\n",
       "300.0     13\n",
       "240.0      4\n",
       "84.0       4\n",
       "120.0      3\n",
       "60.0       2\n",
       "36.0       2\n",
       "12.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Loan_Amount_Term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_rjU-1twSFE",
    "outputId": "6e1e5ba4-204f-4de2-8af9-2e97f3bd0140"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit_History\n",
       "1.0    475\n",
       "0.0     89\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Credit_History'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LU07jGAPCLu_"
   },
   "source": [
    "Na celula abaixo irei preencher os dados categoricos com os valores majoritarios, e os não categoricos `LoanAmount` e `Loan_Amount_Term` irei preencher com média de valor dos mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "eIHiXRFWCUkx"
   },
   "outputs": [],
   "source": [
    "data['Gender'] = data['Gender'].fillna('Male')\n",
    "data['Married'] = data['Married'].fillna('Yes')\n",
    "data['Dependents'] = data['Dependents'].fillna('0')\n",
    "data['Self_Employed'] = data['Self_Employed'].fillna('No')\n",
    "data['LoanAmount'] = data['LoanAmount'].fillna(data['LoanAmount'].mean())\n",
    "data['Loan_Amount_Term'] = data['Loan_Amount_Term'].fillna(data['Loan_Amount_Term'].mean())\n",
    "data['Credit_History'] = data['Credit_History'].fillna(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPz2-N7KCxfD"
   },
   "source": [
    "Checando novamente os valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzcbqqx7mJ6V",
    "outputId": "2a9c71b9-5919-4ac2-bd04-7a6066f41527"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqMoDvIlDIR8"
   },
   "source": [
    "## Transformando dados categóricos\n",
    "\n",
    "Várias colunas do dataframe são categóricas ou seja são caracteres ou strings, logo precisamos transforma-las em valores numericos, são elas: `Gender`, `Married`, `Education`, `Self_Employed` e `Property_Area`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Nt5wel1gDZMk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_381718/1630897239.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data.replace({'Gender': gender_values,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "gender_values = {'Female' : 0, 'Male' : 1} \n",
    "married_values = {'No' : 0, 'Yes' : 1}\n",
    "education_values = {'Graduate' : 0, 'Not Graduate' : 1}\n",
    "employed_values = {'No' : 0, 'Yes' : 1}\n",
    "dependent_values = {'3+': 3, '0': 0, '2': 2, '1': 1}\n",
    "loan_values = {'Y':1,'N':0}\n",
    "area_values = {'Semiurban':2,'Rural':1,'Urban':0}\n",
    "data.replace({'Gender': gender_values,\n",
    "              'Married': married_values, \n",
    "              'Education': education_values,\n",
    "              'Self_Employed': employed_values, \n",
    "              'Dependents': dependent_values,\n",
    "              'Loan_Status': loan_values,\n",
    "              'Property_Area': area_values,\n",
    "              }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXvTWCNiyAK4"
   },
   "source": [
    "Retirando a coluna Loan_id, por se tratar de um codigo identificador ele não pode influenciar em nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "xwSdpIOcDodI"
   },
   "outputs": [],
   "source": [
    "data.drop(['Loan_ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbeZzrH2DxKK"
   },
   "source": [
    "Checando se todos os dados categoricos foram substituidos por valores numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "uCKDHaLWDuCy",
    "outputId": "41889017-9ee9-46f7-9787-91f46c439faa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0       1        0           0          0              0             5849   \n",
       "1       1        1           1          0              0             4583   \n",
       "2       1        1           0          0              1             3000   \n",
       "3       1        1           0          1              0             2583   \n",
       "4       1        0           0          0              0             6000   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                0.0  146.412162             360.0             1.0   \n",
       "1             1508.0  128.000000             360.0             1.0   \n",
       "2                0.0   66.000000             360.0             1.0   \n",
       "3             2358.0  120.000000             360.0             1.0   \n",
       "4                0.0  141.000000             360.0             1.0   \n",
       "\n",
       "   Property_Area  Loan_Status  \n",
       "0              0            1  \n",
       "1              1            0  \n",
       "2              0            1  \n",
       "3              0            1  \n",
       "4              0            1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4lJY-jG55NF"
   },
   "source": [
    "## Separando o dataset em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "MbdgGMF4d2T_"
   },
   "outputs": [],
   "source": [
    "X = data.drop(\"Loan_Status\", axis=1)\n",
    "Y = data[\"Loan_Status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "gcl9XBuyl5LW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set_X, test_set_X, train_set_Y, test_set_Y = train_test_split(X, Y, test_size=0.10, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khEwHOvdITT6"
   },
   "source": [
    "Transformando os dados para que fiquem em uma menor escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "IfKNV8VSmWLU"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_set_X = scaler.fit_transform(train_set_X)\n",
    "test_set_X  = scaler.fit_transform(test_set_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTCylX-dEFlr",
    "outputId": "dd3c915b-3169-4394-c5a5-ff123e74a545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_X:\n",
      " [[-2.02758751  0.73321515  1.2801035  -0.51861886 -0.39652579  1.48071539\n",
      "  -0.54393797 -0.9157385   0.28778621  0.41169348 -1.22874108]\n",
      " [ 0.49319696  0.73321515  0.27922937 -0.51861886 -0.39652579  0.40852018\n",
      "  -0.46477947  1.21341834  0.28778621  0.41169348 -1.22874108]]\n",
      "\n",
      "test_set_X:\n",
      " [[ 0.26261287  0.69006556 -0.89016684 -0.6146363  -0.35675303 -0.74673396\n",
      "  -0.82746285 -1.10113851  0.20754185 -2.4267033  -1.474686  ]\n",
      " [ 0.26261287  0.69006556  1.91612183  1.62697843 -0.35675303 -0.79206856\n",
      "  -0.37295524 -0.53369795  2.14251848  0.41208169  0.93138063]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"train_set_X:\\n\", train_set_X[:2,:])\n",
    "print(\"\\ntest_set_X:\\n\", test_set_X[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPhccdlsEPK1",
    "outputId": "30ad000e-04ee-43fd-b73e-b3a0fd21eccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: n = 11\n",
      "Number of training examples: m = 552\n",
      "Train set X shape: (552, 11)\n",
      "Train set Y shape: (552,)\n",
      "Test set X shape: (62, 11)\n",
      "Test set Y shape: (62,)\n"
     ]
    }
   ],
   "source": [
    "n = train_set_X.shape[1]\n",
    "m = train_set_X.shape[0]\n",
    "\n",
    "print (\"Number of attributes: n = \" + str(n))\n",
    "print (\"Number of training examples: m = \" + str(m))\n",
    "print (\"Train set X shape: \" + str(train_set_X.shape))\n",
    "print (\"Train set Y shape: \" + str(train_set_Y.shape))\n",
    "print (\"Test set X shape: \" + str(test_set_X.shape))\n",
    "print (\"Test set Y shape: \" + str(test_set_Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaiafnLO6T63"
   },
   "source": [
    "## Criando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKjWc70vIjeH"
   },
   "source": [
    "Procurei testar varias configurações de camadas, neurônios e funções de ativação, porem deixei essa que teve um melhor desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "CguTFP7-EWW7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 19:58:39.359877: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-29 19:58:39.376100: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(train_set_X.shape[1])) \n",
    "x = keras.layers.Dense(units=8, activation=\"tanh\")(inputs)\n",
    "x = keras.layers.Dense(units=12, activation=\"tanh\")(inputs)\n",
    "x = keras.layers.Dense(units=8, activation=\"tanh\")(inputs)\n",
    "outputs = keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87N5aloTEb_w",
    "outputId": "9508e49f-d4ce-4fea-8235-825d390a0930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(552, 1)\n"
     ]
    }
   ],
   "source": [
    "processed_data = model(train_set_X)\n",
    "print(processed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wARycn6nEiOX",
    "outputId": "f42818d1-8afb-45b9-c2a7-adfc44b0bc73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 11)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105 (420.00 Byte)\n",
      "Trainable params: 105 (420.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyqv6SuJ22KF"
   },
   "source": [
    "## Compilação\n",
    "\n",
    "Tentei utilizar outras metricas e otimisador, porém obtive um resultado inferior aos que foram apresentados nas aulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "u1S3iVHdEmU8"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"RMSprop\", loss=\"mean_absolute_error\", metrics=[\"accuracy\",\"Precision\",\"Recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etN9Kk1EEslK"
   },
   "source": [
    "## Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtOJXkUTEycW",
    "outputId": "8f17da2f-6e31-4ce1-a2c9-3f1ffc3d9a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.5163 - precision: 0.6687 - recall: 0.5858\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.5471 - precision: 0.6870 - recall: 0.6253\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.5471 - precision: 0.6859 - recall: 0.6280\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.5580 - precision: 0.6923 - recall: 0.6412\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.5580 - precision: 0.6923 - recall: 0.6412\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.5707 - precision: 0.6983 - recall: 0.6596\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.5743 - precision: 0.7000 - recall: 0.6649\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.5833 - precision: 0.7041 - recall: 0.6781\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.5851 - precision: 0.7049 - recall: 0.6807\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.5942 - precision: 0.7100 - recall: 0.6913\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.5960 - precision: 0.7097 - recall: 0.6966\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.6014 - precision: 0.7120 - recall: 0.7045\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.6051 - precision: 0.7135 - recall: 0.7098\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.6087 - precision: 0.7150 - recall: 0.7150\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.6159 - precision: 0.7180 - recall: 0.7256\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.6232 - precision: 0.7209 - recall: 0.7361\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.6250 - precision: 0.7228 - recall: 0.7361\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.6304 - precision: 0.7226 - recall: 0.7493\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.6322 - precision: 0.7234 - recall: 0.7520\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.6431 - precision: 0.7275 - recall: 0.7678\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.6467 - precision: 0.7289 - recall: 0.7731\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.6486 - precision: 0.7295 - recall: 0.7757\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.6558 - precision: 0.7333 - recall: 0.7836\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.6558 - precision: 0.7322 - recall: 0.7863\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.6649 - precision: 0.7377 - recall: 0.7942\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.6685 - precision: 0.7402 - recall: 0.7968\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.6667 - precision: 0.7384 - recall: 0.7968\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.6721 - precision: 0.7403 - recall: 0.8047\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.6757 - precision: 0.7427 - recall: 0.8074\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.6884 - precision: 0.7518 - recall: 0.8153\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.6938 - precision: 0.7549 - recall: 0.8206\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.6975 - precision: 0.7560 - recall: 0.8259\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.6993 - precision: 0.7566 - recall: 0.8285\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.7029 - precision: 0.7578 - recall: 0.8338\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.7047 - precision: 0.7571 - recall: 0.8391\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.7138 - precision: 0.7600 - recall: 0.8522\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3241 - accuracy: 0.7210 - precision: 0.7622 - recall: 0.8628\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3202 - accuracy: 0.7228 - precision: 0.7628 - recall: 0.8654\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.7246 - precision: 0.7646 - recall: 0.8654\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.7283 - precision: 0.7669 - recall: 0.8681\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.7319 - precision: 0.7680 - recall: 0.8734\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.7337 - precision: 0.7685 - recall: 0.8760\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3008 - accuracy: 0.7355 - precision: 0.7691 - recall: 0.8786\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2969 - accuracy: 0.7446 - precision: 0.7729 - recall: 0.8892\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.7428 - precision: 0.7699 - recall: 0.8918\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.7409 - precision: 0.7682 - recall: 0.8918\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.7446 - precision: 0.7705 - recall: 0.8945\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2821 - accuracy: 0.7536 - precision: 0.7730 - recall: 0.9077\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.7572 - precision: 0.7765 - recall: 0.9077\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.7645 - precision: 0.7810 - recall: 0.9129\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2709 - accuracy: 0.7681 - precision: 0.7820 - recall: 0.9182\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.7736 - precision: 0.7835 - recall: 0.9261\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.7754 - precision: 0.7840 - recall: 0.9288\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2603 - accuracy: 0.7808 - precision: 0.7854 - recall: 0.9367\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2569 - accuracy: 0.7808 - precision: 0.7829 - recall: 0.9420\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.7917 - precision: 0.7882 - recall: 0.9525\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.7935 - precision: 0.7899 - recall: 0.9525\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.7917 - precision: 0.7882 - recall: 0.9525\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7953 - precision: 0.7917 - recall: 0.9525\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.7953 - precision: 0.7904 - recall: 0.9551\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.7971 - precision: 0.7908 - recall: 0.9578\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.8025 - precision: 0.7961 - recall: 0.9578\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.8043 - precision: 0.7952 - recall: 0.9631\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.8043 - precision: 0.7952 - recall: 0.9631\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.8080 - precision: 0.7974 - recall: 0.9657\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.8062 - precision: 0.7957 - recall: 0.9657\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.8116 - precision: 0.7983 - recall: 0.9710\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.8080 - precision: 0.7948 - recall: 0.9710\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.8080 - precision: 0.7948 - recall: 0.9710\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.8080 - precision: 0.7948 - recall: 0.9710\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.8098 - precision: 0.7965 - recall: 0.9710\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.8098 - precision: 0.7965 - recall: 0.9710\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.8098 - precision: 0.7965 - recall: 0.9710\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2116 - accuracy: 0.8098 - precision: 0.7965 - recall: 0.9710\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2102 - accuracy: 0.8116 - precision: 0.7970 - recall: 0.9736\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.8116 - precision: 0.7944 - recall: 0.9789\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.8116 - precision: 0.7944 - recall: 0.9789\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.8116 - precision: 0.7944 - recall: 0.9789\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.8116 - precision: 0.7944 - recall: 0.9789\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.8116 - precision: 0.7944 - recall: 0.9789\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.8116 - precision: 0.7944 - recall: 0.9789\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.8116 - precision: 0.7944 - recall: 0.9789\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 128/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 129/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 130/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 131/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 132/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 133/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 134/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.8134 - precision: 0.7961 - recall: 0.9789\n",
      "Epoch 135/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 136/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 137/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 138/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 139/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 140/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 141/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 142/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 143/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 144/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 145/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 146/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 147/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 148/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 149/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 150/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 151/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 152/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 153/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 154/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 155/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 156/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 157/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 158/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.8116 - precision: 0.7957 - recall: 0.9763\n",
      "Epoch 159/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 160/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.8134 - precision: 0.7974 - recall: 0.9763\n",
      "Epoch 161/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 162/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 163/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 164/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 165/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 166/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 167/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 168/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 169/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 170/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 171/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 172/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 173/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 174/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 175/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 176/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 177/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 178/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 179/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 180/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 181/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 182/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 183/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 184/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 185/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 186/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 187/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 188/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.8152 - precision: 0.7991 - recall: 0.9763\n",
      "Epoch 189/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.8170 - precision: 0.7996 - recall: 0.9789\n",
      "Epoch 190/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.8170 - precision: 0.7996 - recall: 0.9789\n",
      "Epoch 191/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.8170 - precision: 0.7996 - recall: 0.9789\n",
      "Epoch 192/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.8170 - precision: 0.7996 - recall: 0.9789\n",
      "Epoch 193/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 194/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 195/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 196/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 197/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 198/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 199/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 200/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 201/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 202/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 203/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 204/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 205/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 206/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 207/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 208/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 209/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 210/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 211/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 212/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 213/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 214/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 215/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 216/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 217/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 218/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 219/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 220/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 221/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 222/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 223/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 224/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 225/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 226/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 227/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 228/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 229/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 230/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 231/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 232/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 233/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 234/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 235/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 236/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 237/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 238/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 239/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 240/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 241/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 242/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 243/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 244/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 245/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 246/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 247/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 248/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 249/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 250/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 251/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 252/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 253/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 254/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 255/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 256/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 257/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 258/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 259/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 260/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 261/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 262/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 263/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 264/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 265/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 266/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 267/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 268/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 269/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 270/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 271/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 272/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 273/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 274/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 275/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 276/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 277/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 278/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 279/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 280/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 281/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 282/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 283/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 284/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 285/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 286/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 287/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 288/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 289/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 290/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 291/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 292/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 293/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 294/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 295/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 296/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 297/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 298/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 299/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 300/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 301/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 302/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 303/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 304/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 305/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 306/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 307/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 308/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 309/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 310/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 311/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 312/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 313/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 314/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 315/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 316/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 317/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 318/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 319/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 320/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 321/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 322/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 323/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 324/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 325/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 326/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 327/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 328/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 329/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 330/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 331/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 332/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 333/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 334/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 335/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 336/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 337/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.8188 - precision: 0.8000 - recall: 0.9815\n",
      "Epoch 338/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 339/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 340/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 341/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 342/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 343/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 344/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 345/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 346/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 347/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 348/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 349/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 350/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 351/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.8207 - precision: 0.8017 - recall: 0.9815\n",
      "Epoch 352/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 353/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 354/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 355/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 356/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 357/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 358/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 359/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 360/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 361/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 362/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 363/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 364/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 365/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 366/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 367/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 368/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 369/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 370/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 371/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 372/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 373/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 374/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 375/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 376/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 377/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 378/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 379/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 380/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 381/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 382/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 383/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 384/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 385/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 386/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 387/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 388/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 389/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 390/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 391/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 392/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 393/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 394/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 395/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 396/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 397/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 398/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 399/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 400/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 401/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 402/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 403/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 404/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 405/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 406/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 407/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 408/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 409/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 410/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 411/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 412/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 413/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 414/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 415/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 416/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 417/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 418/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 419/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 420/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 421/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 422/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 423/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 424/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 425/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 426/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 427/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 428/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 429/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 430/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 431/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 432/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 433/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 434/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 435/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 436/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 437/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 438/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 439/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 440/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 441/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 442/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 443/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 444/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 445/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 446/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 447/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 448/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 449/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 450/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 451/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 452/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 453/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 454/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 455/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 456/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 457/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 458/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 459/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 460/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 461/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 462/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 463/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 464/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 465/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 466/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 467/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 468/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 469/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 470/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 471/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 472/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 473/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 474/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 475/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 476/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 477/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 478/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 479/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 480/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 481/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 482/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 483/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 484/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 485/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 486/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 487/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 488/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 489/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 490/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 491/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 492/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 493/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 494/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 495/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 496/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 497/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 498/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 499/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 500/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 501/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 502/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 503/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 504/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 505/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 506/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 507/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 508/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 509/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 510/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 511/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 512/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 513/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 514/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 515/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 516/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 517/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 518/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 519/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 520/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 521/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 522/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 523/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 524/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 525/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 526/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 527/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 528/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 529/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 530/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 531/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 532/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 533/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 534/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 535/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 536/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 537/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 538/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 539/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 540/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 541/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 542/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 543/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 544/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 545/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.8243 - precision: 0.8052 - recall: 0.9815\n",
      "Epoch 546/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.8243 - precision: 0.8052 - recall: 0.9815\n",
      "Epoch 547/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.8225 - precision: 0.8035 - recall: 0.9815\n",
      "Epoch 548/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.8243 - precision: 0.8052 - recall: 0.9815\n",
      "Epoch 549/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.8243 - precision: 0.8052 - recall: 0.9815\n",
      "Epoch 550/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.8243 - precision: 0.8052 - recall: 0.9815\n",
      "Epoch 551/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.8243 - precision: 0.8052 - recall: 0.9815\n",
      "Epoch 552/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 553/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 554/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.8243 - precision: 0.8052 - recall: 0.9815\n",
      "Epoch 555/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 556/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.8243 - precision: 0.8052 - recall: 0.9815\n",
      "Epoch 557/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 558/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 559/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 560/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1781 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 561/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 562/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 563/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 564/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 565/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 566/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 567/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 568/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 569/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 570/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 571/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 572/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 573/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 574/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 575/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 576/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 577/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 578/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 579/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 580/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 581/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 582/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 583/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 584/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 585/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 586/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 587/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 588/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 589/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 590/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 591/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 592/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 593/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 594/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 595/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 596/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 597/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 598/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 599/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 600/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 601/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 602/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 603/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 604/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 605/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 606/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 607/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 608/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 609/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 610/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 611/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 612/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 613/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 614/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 615/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 616/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 617/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 618/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 619/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 620/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 621/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 622/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 623/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 624/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 625/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 626/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 627/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 628/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 629/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 630/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 631/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 632/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 633/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 634/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 635/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 636/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 637/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 638/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 639/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 640/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 641/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 642/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 643/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 644/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 645/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 646/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 647/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 648/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 649/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 650/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 651/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 652/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 653/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 654/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 655/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 656/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 657/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 658/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 659/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 660/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 661/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 662/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 663/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 664/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 665/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 666/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 667/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 668/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 669/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 670/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 671/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 672/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 673/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 674/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 675/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 676/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 677/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 678/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 679/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 680/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 681/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 682/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 683/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 684/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 685/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 686/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 687/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 688/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 689/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 690/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 691/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 692/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 693/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 694/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 695/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 696/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 697/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 698/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 699/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 700/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 701/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 702/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 703/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 704/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 705/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 706/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 707/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 708/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 709/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 710/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 711/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 712/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 713/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 714/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 715/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 716/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 717/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 718/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 719/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 720/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 721/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 722/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 723/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 724/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 725/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 726/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 727/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 728/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 729/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 730/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 731/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 732/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 733/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 734/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 735/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 736/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 737/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 738/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 739/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 740/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 741/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 742/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 743/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 744/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 745/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 746/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 747/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 748/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 749/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 750/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 751/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 752/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 753/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 754/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 755/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 756/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 757/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 758/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 759/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 760/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 761/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 762/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 763/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 764/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 765/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 766/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 767/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 768/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 769/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 770/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 771/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 772/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 773/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 774/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 775/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 776/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 777/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 778/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 779/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 780/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 781/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 782/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 783/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 784/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 785/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 786/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 787/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 788/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 789/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 790/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 791/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 792/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 793/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 794/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 795/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 796/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 797/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 798/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 799/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 800/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 801/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 802/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 803/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 804/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 805/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 806/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 807/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 808/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 809/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 810/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 811/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 812/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 813/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 814/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 815/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 816/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 817/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 818/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 819/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 820/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 821/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 822/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 823/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 824/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 825/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 826/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 827/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 828/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 829/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 830/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 831/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 832/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 833/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 834/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 835/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 836/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 837/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 838/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 839/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 840/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 841/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 842/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 843/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 844/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 845/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 846/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 847/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 848/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 849/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 850/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 851/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 852/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 853/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 854/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 855/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 856/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 857/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 858/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 859/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 860/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 861/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 862/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 863/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 864/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 865/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 866/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 867/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 868/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 869/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 870/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 871/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 872/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 873/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 874/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 875/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 876/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 877/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 878/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 879/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 880/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 881/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 882/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 883/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 884/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 885/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 886/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 887/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 888/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 889/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 890/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 891/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 892/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 893/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 894/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 895/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 896/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 897/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 898/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 899/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 900/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 901/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 902/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 903/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 904/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 905/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 906/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 907/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 908/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 909/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 910/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 911/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 912/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 913/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 914/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 915/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 916/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 917/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 918/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 919/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 920/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 921/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 922/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 923/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 924/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 925/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 926/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 927/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 928/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 929/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 930/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 931/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 932/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 933/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 934/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 935/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 936/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 937/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 938/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 939/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 940/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 941/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 942/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 943/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 944/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 945/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 946/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 947/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 948/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 949/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 950/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 951/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 952/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 953/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 954/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 955/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 956/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 957/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 958/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 959/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 960/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 961/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 962/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 963/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 964/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 965/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 966/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 967/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 968/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 969/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 970/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 971/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 972/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 973/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 974/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 975/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 976/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 977/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 978/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 979/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 980/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 981/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 982/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 983/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 984/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 985/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 986/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 987/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 988/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 989/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 990/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 991/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 992/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 993/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 994/1000\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 995/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 996/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 997/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 998/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 999/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "Epoch 1000/1000\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.8261 - precision: 0.8069 - recall: 0.9815\n",
      "{'loss': [0.4892778694629669, 0.48108744621276855, 0.47502046823501587, 0.4696490466594696, 0.46433037519454956, 0.45921382308006287, 0.45419034361839294, 0.44918498396873474, 0.44432079792022705, 0.43952062726020813, 0.43467509746551514, 0.42991548776626587, 0.4251832365989685, 0.42049726843833923, 0.41584348678588867, 0.4112749993801117, 0.40686309337615967, 0.4024524390697479, 0.3981166183948517, 0.39384594559669495, 0.3895612061023712, 0.3852735459804535, 0.38093701004981995, 0.376648485660553, 0.3724626898765564, 0.3682919442653656, 0.36429429054260254, 0.3600878119468689, 0.35597938299179077, 0.3520628809928894, 0.3480561375617981, 0.3440435528755188, 0.3400847315788269, 0.33614298701286316, 0.3321874439716339, 0.3281545042991638, 0.32407495379447937, 0.32020092010498047, 0.31629040837287903, 0.3124614953994751, 0.3085240125656128, 0.3046981990337372, 0.30075523257255554, 0.29693421721458435, 0.293121337890625, 0.2894643247127533, 0.28565916419029236, 0.2820636034011841, 0.27830934524536133, 0.274553507566452, 0.27086353302001953, 0.2673654556274414, 0.2638642191886902, 0.26034027338027954, 0.256913959980011, 0.2535351812839508, 0.25025129318237305, 0.2471769005060196, 0.24418672919273376, 0.24121765792369843, 0.23861804604530334, 0.23583227396011353, 0.23318235576152802, 0.2306496649980545, 0.2282327264547348, 0.22597715258598328, 0.22387728095054626, 0.221831277012825, 0.2199000120162964, 0.21799492835998535, 0.2161901444196701, 0.21459265053272247, 0.21309632062911987, 0.2116306871175766, 0.2101830244064331, 0.20887701213359833, 0.20774085819721222, 0.2066037356853485, 0.20556850731372833, 0.20452980697155, 0.2036285549402237, 0.20276395976543427, 0.20197053253650665, 0.2011418342590332, 0.20039454102516174, 0.1997424066066742, 0.19913990795612335, 0.19848404824733734, 0.1979949027299881, 0.19752013683319092, 0.19699528813362122, 0.19658136367797852, 0.19617600739002228, 0.1957305371761322, 0.195475235581398, 0.19502097368240356, 0.19475489854812622, 0.19445852935314178, 0.19419342279434204, 0.19388769567012787, 0.19367700815200806, 0.19342005252838135, 0.1932080090045929, 0.19301630556583405, 0.1928582787513733, 0.19265009462833405, 0.192464217543602, 0.19233208894729614, 0.19219982624053955, 0.19205337762832642, 0.19193895161151886, 0.1917809545993805, 0.19167165458202362, 0.19158847630023956, 0.1914217174053192, 0.19131559133529663, 0.19121506810188293, 0.19113671779632568, 0.1909656971693039, 0.1909329742193222, 0.1908530294895172, 0.19078493118286133, 0.19059708714485168, 0.19062204658985138, 0.19051624834537506, 0.1903761923313141, 0.19026239216327667, 0.19027410447597504, 0.19020548462867737, 0.19018550217151642, 0.18999338150024414, 0.19001324474811554, 0.18986639380455017, 0.18982155621051788, 0.18975651264190674, 0.18973512947559357, 0.1895810067653656, 0.18959906697273254, 0.18951451778411865, 0.18941114842891693, 0.18935543298721313, 0.18925465643405914, 0.18931002914905548, 0.18918024003505707, 0.18911099433898926, 0.189047172665596, 0.1889590322971344, 0.18893101811408997, 0.18884627521038055, 0.18879404664039612, 0.1887286901473999, 0.18861371278762817, 0.18849927186965942, 0.18857115507125854, 0.18841136991977692, 0.18836303055286407, 0.18831872940063477, 0.1882401555776596, 0.1881517767906189, 0.18807071447372437, 0.18796096742153168, 0.18798023462295532, 0.1878567337989807, 0.18784712255001068, 0.18771566450595856, 0.18769027292728424, 0.1876102089881897, 0.18752765655517578, 0.187490314245224, 0.18741370737552643, 0.18737639486789703, 0.18728232383728027, 0.1872101128101349, 0.1871766597032547, 0.18711218237876892, 0.18703167140483856, 0.1869465410709381, 0.18688899278640747, 0.1868264079093933, 0.18676608800888062, 0.18673276901245117, 0.18660221993923187, 0.18658040463924408, 0.1865108460187912, 0.1864183098077774, 0.18639592826366425, 0.1863342970609665, 0.18636050820350647, 0.18616804480552673, 0.1862180531024933, 0.18611757457256317, 0.18606774508953094, 0.18605086207389832, 0.1859281361103058, 0.18593524396419525, 0.18589183688163757, 0.18584150075912476, 0.18576961755752563, 0.18571896851062775, 0.18578748404979706, 0.1856236606836319, 0.185582235455513, 0.1855677217245102, 0.18546481430530548, 0.1854732632637024, 0.18537537753582, 0.18531596660614014, 0.1853475570678711, 0.18529213964939117, 0.1851801574230194, 0.18518662452697754, 0.18511004745960236, 0.18517561256885529, 0.18505331873893738, 0.18503275513648987, 0.18494749069213867, 0.18495145440101624, 0.18489079177379608, 0.18484139442443848, 0.18484660983085632, 0.18480516970157623, 0.18475143611431122, 0.18478186428546906, 0.18461348116397858, 0.1846184879541397, 0.18459932506084442, 0.1845250129699707, 0.18452128767967224, 0.18445894122123718, 0.184456467628479, 0.1843801587820053, 0.18436643481254578, 0.1843755692243576, 0.18432466685771942, 0.18440614640712738, 0.18424025177955627, 0.18419255316257477, 0.184212327003479, 0.18416333198547363, 0.18412406742572784, 0.18408186733722687, 0.18405781686306, 0.18404921889305115, 0.1840519905090332, 0.18400168418884277, 0.1839636117219925, 0.1839626133441925, 0.18384866416454315, 0.18393953144550323, 0.18382380902767181, 0.1837875097990036, 0.18379278481006622, 0.1837153285741806, 0.18373924493789673, 0.18368253111839294, 0.18367864191532135, 0.1836625188589096, 0.183661088347435, 0.18360358476638794, 0.183569997549057, 0.1835480034351349, 0.18347910046577454, 0.18352200090885162, 0.18351112306118011, 0.18342658877372742, 0.18341569602489471, 0.18340805172920227, 0.18335777521133423, 0.18330861628055573, 0.18335390090942383, 0.18331894278526306, 0.18323424458503723, 0.18323922157287598, 0.18321241438388824, 0.18321751058101654, 0.18316595256328583, 0.18317672610282898, 0.18310357630252838, 0.18311676383018494, 0.18313555419445038, 0.18306852877140045, 0.1830373853445053, 0.18303698301315308, 0.18299326300621033, 0.18295401334762573, 0.18295539915561676, 0.18291613459587097, 0.1829964965581894, 0.18286390602588654, 0.1828531175851822, 0.18288426101207733, 0.18287453055381775, 0.1828472912311554, 0.18281866610050201, 0.1827360838651657, 0.1827562302350998, 0.18270044028759003, 0.18274106085300446, 0.18271048367023468, 0.1826363503932953, 0.18264923989772797, 0.1827067732810974, 0.18258988857269287, 0.18262532353401184, 0.1825144737958908, 0.18256749212741852, 0.18252554535865784, 0.1825091540813446, 0.18255838751792908, 0.18247739970684052, 0.18246442079544067, 0.1824110746383667, 0.18240197002887726, 0.18240024149417877, 0.18236839771270752, 0.1823437660932541, 0.18235136568546295, 0.18234145641326904, 0.18233460187911987, 0.18235187232494354, 0.18227358162403107, 0.18220160901546478, 0.18219731748104095, 0.18223464488983154, 0.18222495913505554, 0.18211083114147186, 0.18212337791919708, 0.18217380344867706, 0.18212033808231354, 0.18214941024780273, 0.18208973109722137, 0.18211856484413147, 0.1820635348558426, 0.182054802775383, 0.18204131722450256, 0.18197035789489746, 0.1820334941148758, 0.1819746047258377, 0.1819678246974945, 0.18191485106945038, 0.18193411827087402, 0.1818789392709732, 0.18182344734668732, 0.1818494200706482, 0.18190646171569824, 0.18178677558898926, 0.1818467229604721, 0.18176764249801636, 0.18174335360527039, 0.18177135288715363, 0.18171881139278412, 0.18167605996131897, 0.1817147433757782, 0.1816530078649521, 0.1816105842590332, 0.18164515495300293, 0.1816350519657135, 0.18153510987758636, 0.18158268928527832, 0.18156957626342773, 0.1815381795167923, 0.18149325251579285, 0.18145470321178436, 0.18148986995220184, 0.18150369822978973, 0.18145988881587982, 0.1813960075378418, 0.1814296543598175, 0.1813858449459076, 0.18138891458511353, 0.18134081363677979, 0.1813620775938034, 0.181306391954422, 0.18129314482212067, 0.18131744861602783, 0.181196928024292, 0.18128280341625214, 0.18123303353786469, 0.18117007613182068, 0.18120862543582916, 0.18118253350257874, 0.181162491440773, 0.18119624257087708, 0.18113695085048676, 0.18108271062374115, 0.18110902607440948, 0.18110381066799164, 0.1810571402311325, 0.18105976283550262, 0.18098773062229156, 0.18103939294815063, 0.18095548450946808, 0.1809835135936737, 0.18098242580890656, 0.18091925978660583, 0.1809101551771164, 0.18094226717948914, 0.18089433014392853, 0.18085996806621552, 0.18085385859012604, 0.18082782626152039, 0.1808054894208908, 0.1808328628540039, 0.18083199858665466, 0.18076200783252716, 0.1807965189218521, 0.18073339760303497, 0.18075037002563477, 0.18072281777858734, 0.1807193160057068, 0.18073032796382904, 0.18072542548179626, 0.1806638389825821, 0.1806720346212387, 0.18062403798103333, 0.18061363697052002, 0.18061882257461548, 0.1805926263332367, 0.1805635243654251, 0.18059304356575012, 0.18053875863552094, 0.1805185228586197, 0.180545836687088, 0.18054445087909698, 0.18045009672641754, 0.18048542737960815, 0.18047477304935455, 0.1804785579442978, 0.18039311468601227, 0.18044357001781464, 0.18040698766708374, 0.18044111132621765, 0.18039865791797638, 0.18035833537578583, 0.18038024008274078, 0.18030783534049988, 0.18029050529003143, 0.18033303320407867, 0.18031422793865204, 0.18033067882061005, 0.1802649199962616, 0.18027648329734802, 0.18023809790611267, 0.1802288293838501, 0.18024638295173645, 0.1802244484424591, 0.18014630675315857, 0.18022078275680542, 0.1801856905221939, 0.18023136258125305, 0.18014653027057648, 0.1801179051399231, 0.1801486313343048, 0.1800873875617981, 0.18014998733997345, 0.18005643784999847, 0.18006297945976257, 0.1800498068332672, 0.18012234568595886, 0.18001961708068848, 0.18001291155815125, 0.17996004223823547, 0.180069237947464, 0.17997299134731293, 0.17996148765087128, 0.17997467517852783, 0.17995254695415497, 0.17997530102729797, 0.1799280047416687, 0.17991606891155243, 0.17990979552268982, 0.17989563941955566, 0.1798495203256607, 0.17991197109222412, 0.17986901104450226, 0.1798684298992157, 0.1798318326473236, 0.17980089783668518, 0.17983029782772064, 0.17975854873657227, 0.1797371357679367, 0.17983107268810272, 0.17979440093040466, 0.17971327900886536, 0.17972955107688904, 0.17974385619163513, 0.1797429770231247, 0.1797279715538025, 0.1796802431344986, 0.1796732395887375, 0.17966115474700928, 0.17969198524951935, 0.17964136600494385, 0.1796007603406906, 0.17965738475322723, 0.17961421608924866, 0.179592564702034, 0.17954958975315094, 0.17954900860786438, 0.17954054474830627, 0.17950908839702606, 0.17946583032608032, 0.17954972386360168, 0.17951563000679016, 0.17950569093227386, 0.17946016788482666, 0.17940928041934967, 0.1794949322938919, 0.17940130829811096, 0.17939059436321259, 0.17934824526309967, 0.17941942811012268, 0.1793765425682068, 0.17934255301952362, 0.17937035858631134, 0.17932666838169098, 0.1792983114719391, 0.1792176067829132, 0.1792568415403366, 0.179313525557518, 0.1791766732931137, 0.17920850217342377, 0.17916575074195862, 0.1791890561580658, 0.17919568717479706, 0.17912359535694122, 0.17906694114208221, 0.1790880560874939, 0.17899128794670105, 0.17904351651668549, 0.1789761632680893, 0.17897343635559082, 0.17896758019924164, 0.1788756400346756, 0.1788737177848816, 0.1787910908460617, 0.1788027435541153, 0.17870639264583588, 0.17872114479541779, 0.1787683516740799, 0.1786329746246338, 0.1786145567893982, 0.17862635850906372, 0.17860548198223114, 0.1785041242837906, 0.17853739857673645, 0.178523987531662, 0.17836830019950867, 0.17847156524658203, 0.17842990159988403, 0.17841440439224243, 0.17835840582847595, 0.17831581830978394, 0.1783422976732254, 0.1782902032136917, 0.17835736274719238, 0.17821551859378815, 0.17818540334701538, 0.17812223732471466, 0.17806191742420197, 0.1781264990568161, 0.1781425029039383, 0.17810393869876862, 0.17810514569282532, 0.17798751592636108, 0.17797896265983582, 0.177969828248024, 0.1779506951570511, 0.17797279357910156, 0.17793801426887512, 0.17786601185798645, 0.17786814272403717, 0.17786847054958344, 0.1778450310230255, 0.17794886231422424, 0.1777646243572235, 0.1778097301721573, 0.17772801220417023, 0.17768795788288116, 0.17775098979473114, 0.17768821120262146, 0.1776280254125595, 0.1776381880044937, 0.1775895059108734, 0.17760497331619263, 0.17753584682941437, 0.17756816744804382, 0.1776745617389679, 0.17754220962524414, 0.17746035754680634, 0.1774485856294632, 0.17744150757789612, 0.17748022079467773, 0.17746904492378235, 0.1774170845746994, 0.17741914093494415, 0.177400141954422, 0.1773550659418106, 0.17734472453594208, 0.1773037314414978, 0.1773100644350052, 0.1772499680519104, 0.17726367712020874, 0.17727765440940857, 0.17730854451656342, 0.1772303432226181, 0.1771821528673172, 0.1771765798330307, 0.17716915905475616, 0.17711295187473297, 0.1771382987499237, 0.17708443105220795, 0.1770806908607483, 0.17704416811466217, 0.17715179920196533, 0.17709270119667053, 0.17699399590492249, 0.1770247519016266, 0.17698559165000916, 0.1770012229681015, 0.17701762914657593, 0.17698732018470764, 0.1768736094236374, 0.17684899270534515, 0.17692922055721283, 0.1768781542778015, 0.1768723428249359, 0.17680111527442932, 0.17683088779449463, 0.1768493354320526, 0.1768355518579483, 0.1768254041671753, 0.17678570747375488, 0.17676720023155212, 0.1767348051071167, 0.17674610018730164, 0.1766858547925949, 0.17675277590751648, 0.17661085724830627, 0.17681901156902313, 0.1766391098499298, 0.17659561336040497, 0.17661774158477783, 0.17658749222755432, 0.1766684651374817, 0.17659497261047363, 0.1765831559896469, 0.1765519380569458, 0.17655757069587708, 0.17649656534194946, 0.17651057243347168, 0.1765521913766861, 0.17648106813430786, 0.17650099098682404, 0.17644758522510529, 0.17644061148166656, 0.1764421910047531, 0.17641717195510864, 0.17637106776237488, 0.17639678716659546, 0.17636123299598694, 0.17641404271125793, 0.17631842195987701, 0.17632588744163513, 0.17635110020637512, 0.17625251412391663, 0.1763225942850113, 0.17628832161426544, 0.17626459896564484, 0.17626391351222992, 0.17624546587467194, 0.1762733906507492, 0.17618802189826965, 0.17618027329444885, 0.17617470026016235, 0.17620572447776794, 0.17620554566383362, 0.17617730796337128, 0.17612816393375397, 0.17613603174686432, 0.17612388730049133, 0.17608413100242615, 0.17609190940856934, 0.17606095969676971, 0.1760525405406952, 0.17606154084205627, 0.17603354156017303, 0.17604570090770721, 0.17604002356529236, 0.17601355910301208, 0.17604799568653107, 0.17600111663341522, 0.17597688734531403, 0.17595641314983368, 0.17596392333507538, 0.17595382034778595, 0.1759350597858429, 0.1759437620639801, 0.17588743567466736, 0.1758849322795868, 0.17589135468006134, 0.17584381997585297, 0.17584626376628876, 0.17588621377944946, 0.1758614480495453, 0.17584167420864105, 0.1757999211549759, 0.17580363154411316, 0.17580021917819977, 0.1757574826478958, 0.17579838633537292, 0.17574124038219452, 0.17572945356369019, 0.17581592500209808, 0.17571072280406952, 0.17570297420024872, 0.17569592595100403, 0.17567166686058044, 0.17567041516304016, 0.17566347122192383, 0.17567190527915955, 0.17563427984714508, 0.17566274106502533, 0.17560529708862305, 0.1756129264831543, 0.1756274700164795, 0.17559286952018738, 0.1755627989768982, 0.17555534839630127, 0.17561635375022888, 0.17555417120456696, 0.17551562190055847, 0.1755249947309494, 0.17554473876953125, 0.17551590502262115, 0.17551325261592865, 0.17549355328083038, 0.1755111813545227, 0.175489142537117, 0.1754845678806305, 0.175471231341362, 0.17546363174915314, 0.175435408949852, 0.1754193753004074, 0.17542357742786407, 0.17540335655212402, 0.17538228631019592, 0.1754002869129181, 0.1753939539194107, 0.17540693283081055, 0.1753416508436203, 0.17532432079315186, 0.17533420026302338, 0.17533135414123535, 0.17531020939350128, 0.17531445622444153, 0.17532050609588623, 0.17528791725635529, 0.17527461051940918, 0.1752890795469284, 0.1752648800611496, 0.17528368532657623, 0.17525498569011688, 0.1752621829509735, 0.17524440586566925, 0.17522679269313812, 0.1752401739358902, 0.1752030849456787, 0.17519626021385193, 0.17521294951438904, 0.17522166669368744, 0.17517231404781342, 0.17518284916877747, 0.1751669943332672, 0.17514978349208832, 0.17513789236545563, 0.17515063285827637, 0.17513646185398102, 0.17512686550617218, 0.17510950565338135, 0.1750987023115158, 0.17511048913002014, 0.17510849237442017, 0.1750810593366623, 0.17507314682006836, 0.1750706434249878, 0.1750793159008026, 0.17505009472370148, 0.17507949471473694, 0.1750292330980301, 0.1750364899635315, 0.17502784729003906, 0.17502181231975555, 0.17502255737781525, 0.17501267790794373, 0.17499732971191406, 0.17497149109840393, 0.17498508095741272, 0.1749824732542038, 0.1749778389930725, 0.17495769262313843, 0.17495407164096832, 0.1749401092529297, 0.17494849860668182, 0.17492897808551788, 0.17493344843387604, 0.17491509020328522, 0.1749172955751419, 0.17489972710609436, 0.1748955100774765, 0.17490658164024353, 0.17488089203834534, 0.17487728595733643, 0.17486724257469177, 0.17487286031246185, 0.17484867572784424, 0.17483869194984436, 0.17484602332115173, 0.17482933402061462, 0.1748591512441635, 0.17482832074165344, 0.1748034805059433, 0.1748257577419281, 0.1748272329568863, 0.17482155561447144, 0.1748005747795105, 0.17481502890586853, 0.17477908730506897, 0.17478255927562714, 0.17477594316005707, 0.17475485801696777, 0.17475397884845734, 0.17476852238178253, 0.17476339638233185, 0.1747349500656128, 0.1747439056634903, 0.17472536861896515, 0.1747620403766632, 0.17472538352012634, 0.17472998797893524, 0.17472198605537415, 0.17472775280475616, 0.17471668124198914, 0.17470139265060425, 0.17470255494117737, 0.1746857464313507, 0.17467881739139557, 0.17469364404678345, 0.17467965185642242, 0.17467157542705536, 0.1746719777584076, 0.17466440796852112, 0.17465293407440186, 0.17465847730636597, 0.17465953528881073, 0.17463268339633942, 0.17464189231395721, 0.1746354103088379, 0.17464250326156616, 0.17463324964046478, 0.1746111959218979, 0.17461925745010376, 0.1746027022600174, 0.1746162474155426, 0.1745978593826294, 0.1746102124452591, 0.1745888590812683, 0.17458079755306244, 0.17458289861679077, 0.17458365857601166, 0.17457644641399384, 0.17457154393196106, 0.17456132173538208, 0.17457334697246552, 0.17455802857875824, 0.17455025017261505, 0.17454710602760315, 0.17453472316265106, 0.17456406354904175, 0.17453047633171082, 0.1745295524597168, 0.17452599108219147, 0.1745186746120453, 0.1745261400938034, 0.17451360821723938, 0.17451982200145721, 0.17453116178512573, 0.17449608445167542, 0.17449581623077393, 0.17449656128883362, 0.1744949221611023, 0.17449067533016205, 0.17449907958507538, 0.17448246479034424, 0.1744866520166397, 0.17447349429130554, 0.17448078095912933, 0.17446273565292358, 0.17447729408740997, 0.1744607836008072, 0.1744552105665207, 0.17446304857730865, 0.17445318400859833, 0.17444589734077454, 0.17444942891597748, 0.1744542121887207, 0.174433633685112, 0.17443126440048218, 0.17443589866161346, 0.1744246482849121, 0.17442846298217773, 0.17443342506885529, 0.1744188666343689, 0.17441409826278687, 0.17441704869270325, 0.17441324889659882, 0.1744156777858734, 0.17440290749073029, 0.17440016567707062, 0.1744024157524109, 0.17439165711402893, 0.1743854582309723, 0.17438814043998718, 0.17439594864845276, 0.17438526451587677, 0.17439064383506775, 0.1743820458650589, 0.1743767112493515, 0.17436829209327698, 0.17437094449996948, 0.1743641346693039, 0.17436398565769196, 0.17435705661773682, 0.17435534298419952, 0.17435267567634583, 0.17435817420482635, 0.1743488907814026, 0.17434827983379364, 0.17435623705387115, 0.1743418425321579, 0.17434151470661163, 0.17434071004390717, 0.17433615028858185, 0.17433486878871918, 0.17432063817977905, 0.17432311177253723, 0.17432717978954315, 0.17431804537773132, 0.17432227730751038, 0.17431870102882385, 0.1743151843547821, 0.17431491613388062, 0.17430877685546875, 0.17431044578552246, 0.17430424690246582, 0.1743023842573166, 0.17430248856544495, 0.17429721355438232, 0.17429807782173157, 0.17429353296756744, 0.17429418861865997, 0.17428132891654968, 0.1742929220199585, 0.17428062856197357, 0.17427955567836761, 0.17427633702754974, 0.17427539825439453, 0.17427490651607513, 0.17427629232406616, 0.17426827549934387, 0.17427480220794678, 0.17427478730678558, 0.17426149547100067, 0.17425979673862457, 0.17425537109375, 0.17426112294197083, 0.17425024509429932, 0.17425329983234406, 0.17424887418746948, 0.17424412071704865, 0.17424540221691132, 0.17424404621124268, 0.1742410659790039, 0.17424127459526062, 0.17424574494361877, 0.17423371970653534, 0.17422859370708466, 0.17422907054424286, 0.17422588169574738, 0.17421922087669373, 0.17421813309192657, 0.1742154061794281, 0.17421282827854156, 0.17420774698257446, 0.17420461773872375, 0.17419786751270294, 0.17420092225074768, 0.17419543862342834, 0.17419162392616272, 0.17418062686920166], 'accuracy': [0.5163043737411499, 0.5471014380455017, 0.5471014380455017, 0.5579710006713867, 0.5579710006713867, 0.570652186870575, 0.5742753744125366, 0.5833333134651184, 0.5851449370384216, 0.5942028760910034, 0.5960144996643066, 0.6014492511749268, 0.6050724387168884, 0.6086956262588501, 0.6159420013427734, 0.6231883764266968, 0.625, 0.6304348111152649, 0.6322463750839233, 0.6431159377098083, 0.64673912525177, 0.6485507488250732, 0.6557971239089966, 0.6557971239089966, 0.6648550629615784, 0.66847825050354, 0.6666666865348816, 0.6721014380455017, 0.6757246255874634, 0.6884058117866516, 0.6938405632972717, 0.6974637508392334, 0.6992753744125366, 0.7028985619544983, 0.7047101259231567, 0.7137681245803833, 0.7210144996643066, 0.7228260636329651, 0.7246376872062683, 0.72826087474823, 0.7318840622901917, 0.7336956262588501, 0.7355072498321533, 0.7445651888847351, 0.7427536249160767, 0.7409420013427734, 0.7445651888847351, 0.7536231875419617, 0.7572463750839233, 0.7644927501678467, 0.7681159377098083, 0.7735507488250732, 0.7753623127937317, 0.7807971239089966, 0.7807971239089966, 0.7916666865348816, 0.79347825050354, 0.7916666865348816, 0.7952898740768433, 0.7952898740768433, 0.7971014380455017, 0.8025362491607666, 0.804347813129425, 0.804347813129425, 0.8079710006713867, 0.8061594367027283, 0.8115941882133484, 0.8079710006713867, 0.8079710006713867, 0.8079710006713867, 0.8097826242446899, 0.8097826242446899, 0.8097826242446899, 0.8097826242446899, 0.8115941882133484, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8115941882133484, 0.8134058117866516, 0.8115941882133484, 0.8115941882133484, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8115941882133484, 0.8115941882133484, 0.8134058117866516, 0.8115941882133484, 0.8115941882133484, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8115941882133484, 0.8134058117866516, 0.8115941882133484, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8134058117866516, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8115941882133484, 0.8134058117866516, 0.8115941882133484, 0.8134058117866516, 0.8134058117866516, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8152173757553101, 0.8170289993286133, 0.8170289993286133, 0.8170289993286133, 0.8170289993286133, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.820652186870575, 0.8188405632972717, 0.8188405632972717, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.8188405632972717, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.820652186870575, 0.8188405632972717, 0.8188405632972717, 0.820652186870575, 0.8188405632972717, 0.8188405632972717, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.8188405632972717, 0.820652186870575, 0.820652186870575, 0.8188405632972717, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.8188405632972717, 0.820652186870575, 0.820652186870575, 0.8188405632972717, 0.820652186870575, 0.8188405632972717, 0.820652186870575, 0.820652186870575, 0.8188405632972717, 0.820652186870575, 0.820652186870575, 0.8224637508392334, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.820652186870575, 0.8224637508392334, 0.820652186870575, 0.820652186870575, 0.8224637508392334, 0.820652186870575, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8224637508392334, 0.8242753744125366, 0.8242753744125366, 0.8224637508392334, 0.8242753744125366, 0.8242753744125366, 0.8242753744125366, 0.8242753744125366, 0.8260869383811951, 0.8260869383811951, 0.8242753744125366, 0.8260869383811951, 0.8242753744125366, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951, 0.8260869383811951], 'precision': [0.6686747074127197, 0.686956524848938, 0.6858789920806885, 0.692307710647583, 0.692307710647583, 0.6983240246772766, 0.699999988079071, 0.7041096091270447, 0.7049180269241333, 0.7100270986557007, 0.7096773982048035, 0.7120000123977661, 0.7135278582572937, 0.7150395512580872, 0.7180156707763672, 0.7209302186965942, 0.7227979302406311, 0.7226462960243225, 0.7233502268791199, 0.7275000214576721, 0.7288557291030884, 0.729528546333313, 0.7333333492279053, 0.7321867346763611, 0.7377451062202454, 0.7401960492134094, 0.738386332988739, 0.7402912378311157, 0.7427184581756592, 0.7518247961997986, 0.7548543810844421, 0.7560386657714844, 0.7566264867782593, 0.7577937841415405, 0.7571428418159485, 0.7599999904632568, 0.7622377872467041, 0.7627906799316406, 0.7645687460899353, 0.7668997645378113, 0.7679814100265503, 0.7685185074806213, 0.7690531015396118, 0.7729358077049255, 0.7699316740036011, 0.7681818008422852, 0.7704545259475708, 0.7730336785316467, 0.7765237092971802, 0.7810384035110474, 0.7820224761962891, 0.7834821343421936, 0.7839643359184265, 0.7853982448577881, 0.7828947305679321, 0.7882096171379089, 0.7899343371391296, 0.7882096171379089, 0.7916666865348816, 0.7903929948806763, 0.7908496856689453, 0.7960526347160339, 0.7952069640159607, 0.7952069640159607, 0.7973856329917908, 0.7956521511077881, 0.7982646226882935, 0.7948164343833923, 0.7948164343833923, 0.7948164343833923, 0.7965368032455444, 0.7965368032455444, 0.7965368032455444, 0.7965368032455444, 0.7969762682914734, 0.7974137663841248, 0.7974137663841248, 0.7974137663841248, 0.7974137663841248, 0.7974137663841248, 0.7974137663841248, 0.7974137663841248, 0.7974137663841248, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.794432520866394, 0.7961373329162598, 0.794432520866394, 0.794432520866394, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.794432520866394, 0.794432520866394, 0.7961373329162598, 0.794432520866394, 0.794432520866394, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7956989407539368, 0.7961373329162598, 0.7956989407539368, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7961373329162598, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7956989407539368, 0.7974137663841248, 0.7956989407539368, 0.7974137663841248, 0.7974137663841248, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7991360425949097, 0.7995689511299133, 0.7995689511299133, 0.7995689511299133, 0.7995689511299133, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.8017241358757019, 0.800000011920929, 0.800000011920929, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.800000011920929, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.8017241358757019, 0.800000011920929, 0.800000011920929, 0.8017241358757019, 0.800000011920929, 0.800000011920929, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.8017241358757019, 0.8017241358757019, 0.800000011920929, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.800000011920929, 0.8017241358757019, 0.8017241358757019, 0.800000011920929, 0.8017241358757019, 0.800000011920929, 0.8017241358757019, 0.8017241358757019, 0.800000011920929, 0.8017241358757019, 0.8017241358757019, 0.8034557104110718, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8017241358757019, 0.8034557104110718, 0.8017241358757019, 0.8017241358757019, 0.8034557104110718, 0.8017241358757019, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8034557104110718, 0.8051947951316833, 0.8051947951316833, 0.8034557104110718, 0.8051947951316833, 0.8051947951316833, 0.8051947951316833, 0.8051947951316833, 0.8069414496421814, 0.8069414496421814, 0.8051947951316833, 0.8069414496421814, 0.8051947951316833, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814, 0.8069414496421814], 'recall': [0.5857519507408142, 0.6253297924995422, 0.6279683113098145, 0.6411609649658203, 0.6411609649658203, 0.6596305966377258, 0.6649076342582703, 0.6781002879142761, 0.6807388067245483, 0.6912928819656372, 0.6965699195861816, 0.7044854760169983, 0.7097625136375427, 0.7150395512580872, 0.7255936861038208, 0.7361477613449097, 0.7361477613449097, 0.7493403553962708, 0.751978874206543, 0.767810046672821, 0.7730870842933655, 0.7757256031036377, 0.7836411595344543, 0.7862796783447266, 0.7941952347755432, 0.7968337535858154, 0.7968337535858154, 0.8047493696212769, 0.8073878884315491, 0.8153034448623657, 0.8205804824829102, 0.8258575201034546, 0.8284960389137268, 0.8337730765342712, 0.8390501141548157, 0.8522427678108215, 0.8627968430519104, 0.8654353618621826, 0.8654353618621826, 0.8680738806724548, 0.8733509182929993, 0.8759894371032715, 0.8786279559135437, 0.8891820311546326, 0.8918206095695496, 0.8918206095695496, 0.8944591283798218, 0.9076517224311829, 0.9076517224311829, 0.9129287600517273, 0.9182057976722717, 0.9261213541030884, 0.9287598729133606, 0.936675488948822, 0.9419525265693665, 0.9525066018104553, 0.9525066018104553, 0.9525066018104553, 0.9525066018104553, 0.9551451206207275, 0.9577836394309998, 0.9577836394309998, 0.9630606770515442, 0.9630606770515442, 0.9656991958618164, 0.9656991958618164, 0.9709762334823608, 0.9709762334823608, 0.9709762334823608, 0.9709762334823608, 0.9709762334823608, 0.9709762334823608, 0.9709762334823608, 0.9709762334823608, 0.9736147522926331, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9762532711029053, 0.9788918495178223, 0.9762532711029053, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9762532711029053, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9788918495178223, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945, 0.9815303683280945]}\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set_X, train_set_Y, batch_size=64, epochs=1000)\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBNaEuaC2HmH"
   },
   "source": [
    "## Avaliação do Modelo\n",
    "\n",
    "Avalie o desempenho da rede no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsUnTHll17nq",
    "outputId": "32c45e2d-a252-49b6-baa5-e63f286973ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1923 - accuracy: 0.8065 - precision: 0.8039 - recall: 0.9535\n",
      "Loss: 0.19 \n",
      "Accuracy: 0.81 \n",
      "Precision: 0.80 \n",
      "Recall: 0.95\n"
     ]
    }
   ],
   "source": [
    "loss, acc, prec, rec = model.evaluate(test_set_X, test_set_Y)\n",
    "print(\"Loss: %.2f\" % loss,  \"\\nAccuracy: %.2f\" % acc, \"\\nPrecision: %.2f\" % prec, \"\\nRecall: %.2f\" % rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzP_s2fL2WoD"
   },
   "source": [
    "## Predição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbY10LPvFGhq",
    "outputId": "0adfbf4c-a982-4247-b5ca-1babc60c5509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "Predictions:  [0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "\n",
      "Correct:      [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_set_X)\n",
    "print(\"Predictions: \", [round(x[0]) for x in predictions])\n",
    "print(\"\\nCorrect:     \", [round(x) for x in test_set_Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Swi-Jo_RkAj"
   },
   "source": [
    "## Comparação com outros modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auS00JC1RpMy"
   },
   "source": [
    "Infelizmente não encontrei outro modelo de deep learning para este dataset, porém comparando com um modelo de machine learning apresentado pela usuária [Rakshmitha Madhevan](https://www.kaggle.com/rakshmithamadhevan) e com meu próprio modelo de machine learning, o nosso modelo em deep learning apresenta um resultado superior, enquanto os modelos em machine learning apresentam uma acurácia por volta de 78% nosso modelo aponta para uma acurácia de 82% aproximadamente.\n",
    "\n",
    "Modelo em machine learning postado no Keagle de autoria da Rakshmitha Madhevan: https://www.kaggle.com/rakshmithamadhevan/are-you-getting-the-loan-loan-status-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xbv0fTdOUoUG"
   },
   "source": [
    "## Agradecimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKAAKE31UuZE"
   },
   "source": [
    "Gostaria de agradecer ao professor Denilson por nos oferecer esse curso introdutório de Redes Neurais e Deep Learning, com toda certeza ajudou muito em minha caminha pela busca de adquirir conhecimentos em inteliência artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVLGv93DL41R"
   },
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e8UhURwL-CF"
   },
   "source": [
    "GITHUB. **An overview of activation functions used in neural networks**.\n",
    "Disponível em: https://adl1995.github.io/an-overview-of-activation-functions-used-in-neural-networks.html. Acesso em: 3 ago. 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c9KLGiKM2tk"
   },
   "source": [
    "MACHINELEARNINGMASTERY. **How to Choose an Activation Function for Deep Learning**. \n",
    "Dispinível em: https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/. Acesso 3 ago. 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXIdTkeENo3Y"
   },
   "source": [
    "TOWARDSDATASCIENCE. **Deep Learning: Which Loss and Activation Functions should I use?**. Disponível em: https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8 Acesso em: 3 ago. 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7jBJ73IQ6Tx"
   },
   "source": [
    "PLURALSIGHT. **A Deep Learning Model to Perform Binary Classification**. Disponível em: https://www.pluralsight.com/guides/deep-learning-model-perform-binary-classification. Acesso em 3 ago. 2021."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6IJSazRK41Sc",
    "bA5vu4K346E-",
    "tjvV7o1t5ojW",
    "HqMoDvIlDIR8",
    "N4lJY-jG55NF",
    "zaiafnLO6T63"
   ],
   "name": "Eduardo_Cezar_Carvalho_Loan_ann_exerc_03_projeto.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
